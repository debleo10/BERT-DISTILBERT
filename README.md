DistilBERT Fine-Tuning for Sentiment Prediction
This project fine-tunes the DistilBERT model by adding custom layers based on the CLS embeddings for sentiment prediction. The aim is to build a lightweight yet powerful model capable of classifying text data into sentiment categories (e.g., positive, negative).
Introduction
DistilBERT is a smaller, faster, cheaper, and lighter version of BERT, achieving competitive performance. This project fine-tunes DistilBERT by adding custom layers to the CLS token's embeddings for sentiment analysis. The final model can be used to classify text into various sentiment categories, which is useful in tasks such as customer feedback analysis, social media monitoring, and more.
